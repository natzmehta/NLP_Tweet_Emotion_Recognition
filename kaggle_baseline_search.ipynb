{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = 'C:/Users/shaur/Desktop/UTD/ANLP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = Path(basepath)\n",
    "data_folder = base_folder/'datasets/emotion'\n",
    "model_folder = base_folder/'models/nlp_spring_2024/emotion/nn'\n",
    "custom_functions = base_folder/'custom_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(str(custom_functions))\n",
    "model_folder.mkdir(exist_ok=True, parents = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shaur\\anaconda3\\envs\\anlp\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# For working with textual data vocabularies and for displaying model summaries\n",
    "from torchtext.vocab import vocab\n",
    "\n",
    "# General-purpose Python libraries for random number generation and numerical operations\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Utilities for efficient serialization/deserialization of Python objects and for element tallying\n",
    "import joblib\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# For creating lightweight attribute classes and for partial function application\n",
    "from functools import partial\n",
    "\n",
    "# For filesystem path handling, generating and displaying confusion matrices, and date-time manipulations\n",
    "from sklearn.metrics import multilabel_confusion_matrix, hamming_loss, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import string\n",
    "\n",
    "# For plotting and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from kaggle import api\n",
    "\n",
    "### NEW ##########################\n",
    "# imports from Huggingface ecosystem\n",
    "import evaluate\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoConfig\n",
    "from transformers import pipeline\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_folder/'train.csv')\n",
    "test = pd.read_csv(data_folder/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“Worry is a down payment on a problem you may ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whatever you decide to do make sure it makes y...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Max_Kellerman  it also helps that the majorit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Accept the challenges so that you can literall...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My roommate: it's okay that we can't spell bec...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  anger  anticipation  \\\n",
       "0  “Worry is a down payment on a problem you may ...      0             1   \n",
       "1  Whatever you decide to do make sure it makes y...      0             0   \n",
       "2  @Max_Kellerman  it also helps that the majorit...      1             0   \n",
       "3  Accept the challenges so that you can literall...      0             0   \n",
       "4  My roommate: it's okay that we can't spell bec...      1             0   \n",
       "\n",
       "   disgust  fear  joy  love  optimism  pessimism  sadness  surprise  trust  \n",
       "0        0     0    0     0         1          0        0         0      1  \n",
       "1        0     0    1     1         1          0        0         0      0  \n",
       "2        1     0    1     0         1          0        0         0      0  \n",
       "3        0     0    1     0         1          0        0         0      0  \n",
       "4        1     0    0     0         0          0        0         0      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop(columns=['ID'], inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emoji_regexp():\n",
    "    emojis = sorted(emoji.EMOJI_DATA, key=len, reverse=True)\n",
    "    pattern = u'(' + u'|'.join(re.escape(u) for u in emojis) + u')'\n",
    "    return re.compile(pattern)\n",
    "\n",
    "def strip_emoji(text):\n",
    "    return re.sub(get_emoji_regexp(), r\"\", text)\n",
    "\n",
    "def strip_all_entities(text): \n",
    "    text = text.replace('\\r', '').replace('\\n', ' ').replace('\\n', ' ').lower()\n",
    "    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text) #remove links and mentions\n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r'', text) #remove non utf8/ascii characters such as '\\x9a\\x91\\x97\\x9a\\x97'\n",
    "    banned_list= string.punctuation + 'Ã'+'±'+'ã'+'¼'+'â'+'»'+'§'\n",
    "    table = str.maketrans('', '', banned_list)\n",
    "    text = text.translate(table)\n",
    "    return text\n",
    "\n",
    "def clean_hashtags(tweet):\n",
    "    new_tweet = \" \".join(word.strip() for word in re.split('#(?!(?:hashtag)\\b)[\\w-]+(?=(?:\\s+#[\\w-]+)*\\s*$)', tweet)) #remove last hashtags\n",
    "    new_tweet2 = \" \".join(word.strip() for word in re.split('#|_', new_tweet)) #remove hashtags symbol from words in the middle of the sentence\n",
    "    return new_tweet2\n",
    "\n",
    "#Filter special characters such as & and $ present in some words\n",
    "def filter_chars(a):\n",
    "    sent = []\n",
    "    for word in a.split(' '):\n",
    "        if ('$' in word) | ('&' in word):\n",
    "            sent.append('')\n",
    "        else:\n",
    "            sent.append(word)\n",
    "    return ' '.join(sent)\n",
    "\n",
    "def remove_mult_spaces(text): # remove multiple spaces\n",
    "    return re.sub(\"\\s\\s+\" , \" \", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocess based on tweet length**\n",
    "\n",
    "**Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean = train['Tweet'].apply(strip_emoji).apply(strip_all_entities).apply(clean_hashtags).apply(filter_chars).apply(remove_mult_spaces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Tweet'] = train_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train['Tweet'].values\n",
    "y = train.loc[:, train.columns != 'Tweet'].values\n",
    "y = np.array(y, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val  = train_test_split(X, y, random_state=42,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Dataset.from_dict({\n",
    "    'texts': X_train,\n",
    "    'labels': y_train\n",
    "})\n",
    "validset = Dataset.from_dict({\n",
    "    'texts': X_val,\n",
    "    'labels': y_val\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['texts', 'labels'],\n",
       "    num_rows: 6951\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"anger\", 1: \"anticipation\", 2: \"disgust\", 3: \"fear\", 4: \"joy\", 5: \"love\", 6: \"optimism\", 7: \"pessimism\", 8: \"sadness\", 9: \"surprise\", 10: \"trust\"}\n",
    "label2id = {id2label[k]: k for k in id2label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = nn.functional.sigmoid(torch.Tensor(logits))\n",
    "    predictions = (predictions >= 0.5).int().numpy()\n",
    "\n",
    "    overall_accuracy = accuracy_score(labels, predictions)\n",
    "    overall_f1 = f1_score(labels, predictions, average='macro', zero_division=0)\n",
    "\n",
    "    return {\n",
    "        'eval_accuracy': overall_accuracy,\n",
    "        'eval_f1': overall_f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distillbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "    return tokenizer(text = batch[\"texts\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6951/6951 [00:00<00:00, 25239.07 examples/s]\n",
      "Map: 100%|██████████| 773/773 [00:00<00:00, 30689.25 examples/s]\n"
     ]
    }
   ],
   "source": [
    "trainset_tokenized = trainset.map(tokenize_fn, batched=True)\n",
    "validset_tokenized = validset.map(tokenize_fn, batched=True)\n",
    "trainset_tokenized = trainset_tokenized.remove_columns(['texts'])\n",
    "validset_tokenized = validset_tokenized.remove_columns(['texts'])\n",
    "trainset_tokenized.set_format(type='torch')\n",
    "validset_tokenized.set_format(type='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, \n",
    "    problem_type=\"multi_label_classification\", \n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=3,\n",
    "\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,  \n",
    "    learning_rate=2e-5, \n",
    "    optim='adamw_torch',\n",
    "\n",
    "    # Checkpoint saving and model evaluation settings\n",
    "    output_dir=str(model_folder), \n",
    "    evaluation_strategy='steps', \n",
    "    eval_steps=100, \n",
    "    save_strategy=\"steps\", \n",
    "    save_steps=100, \n",
    "    load_best_model_at_end=True, \n",
    "    save_total_limit=2, \n",
    "    metric_for_best_model=\"loss\",\n",
    "    greater_is_better=False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shaur\\anaconda3\\envs\\anlp\\lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=trainset_tokenized,\n",
    "    eval_dataset=validset_tokenized,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshauryat1298\u001b[0m (\u001b[33mshauryat12\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\shaur\\Desktop\\UTD\\ANLP\\Assignments\\Emotion Detection\\wandb\\run-20240405_170942-uis7iza5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shauryat12/huggingface/runs/uis7iza5/workspace' target=\"_blank\">trill-dominion-7</a></strong> to <a href='https://wandb.ai/shauryat12/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shauryat12/huggingface' target=\"_blank\">https://wandb.ai/shauryat12/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shauryat12/huggingface/runs/uis7iza5/workspace' target=\"_blank\">https://wandb.ai/shauryat12/huggingface/runs/uis7iza5/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      "  8%|▊         | 100/1305 [00:36<06:51,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.10996119016817593, 'eval_f1': 0.19404651334790357, 'eval_loss': 0.42624354362487793, 'eval_runtime': 2.3533, 'eval_samples_per_second': 328.479, 'eval_steps_per_second': 20.822, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 15%|█▌        | 200/1305 [01:13<06:14,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.17205692108667528, 'eval_f1': 0.27637320008856747, 'eval_loss': 0.38618406653404236, 'eval_runtime': 2.3257, 'eval_samples_per_second': 332.373, 'eval_steps_per_second': 21.069, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 23%|██▎       | 300/1305 [01:50<05:33,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.1979301423027167, 'eval_f1': 0.33622903187755776, 'eval_loss': 0.36491602659225464, 'eval_runtime': 2.3291, 'eval_samples_per_second': 331.891, 'eval_steps_per_second': 21.038, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 31%|███       | 400/1305 [02:27<05:02,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.20439844760672704, 'eval_f1': 0.38143542615023107, 'eval_loss': 0.34839388728141785, 'eval_runtime': 2.3336, 'eval_samples_per_second': 331.248, 'eval_steps_per_second': 20.998, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 500/1305 [03:02<04:26,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3914, 'grad_norm': 1.239598035812378, 'learning_rate': 1.2337164750957855e-05, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 38%|███▊      | 500/1305 [03:04<04:26,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.22509702457956016, 'eval_f1': 0.40949739569983484, 'eval_loss': 0.3393385410308838, 'eval_runtime': 2.108, 'eval_samples_per_second': 366.695, 'eval_steps_per_second': 23.245, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 46%|████▌     | 600/1305 [03:41<03:57,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.23027166882276842, 'eval_f1': 0.4260116546964896, 'eval_loss': 0.33513087034225464, 'eval_runtime': 2.3116, 'eval_samples_per_second': 334.399, 'eval_steps_per_second': 21.197, 'epoch': 1.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 54%|█████▎    | 700/1305 [04:18<03:29,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.23932729624838292, 'eval_f1': 0.40870083768703597, 'eval_loss': 0.3297160267829895, 'eval_runtime': 2.3309, 'eval_samples_per_second': 331.633, 'eval_steps_per_second': 21.022, 'epoch': 1.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 61%|██████▏   | 800/1305 [04:56<02:54,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.24320827943078913, 'eval_f1': 0.42928156529982364, 'eval_loss': 0.32653161883354187, 'eval_runtime': 2.3983, 'eval_samples_per_second': 322.31, 'eval_steps_per_second': 20.431, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 69%|██████▉   | 900/1305 [05:32<02:14,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.23673997412677877, 'eval_f1': 0.42929089596846626, 'eval_loss': 0.3258562386035919, 'eval_runtime': 2.317, 'eval_samples_per_second': 333.617, 'eval_steps_per_second': 21.148, 'epoch': 2.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1000/1305 [06:07<01:42,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2987, 'grad_norm': 1.2275941371917725, 'learning_rate': 4.674329501915709e-06, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 77%|███████▋  | 1000/1305 [06:09<01:42,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.24191461836998707, 'eval_f1': 0.4403509647022407, 'eval_loss': 0.32408905029296875, 'eval_runtime': 2.0901, 'eval_samples_per_second': 369.843, 'eval_steps_per_second': 23.444, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 84%|████████▍ | 1100/1305 [06:46<01:09,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.23544631306597671, 'eval_f1': 0.450338055277501, 'eval_loss': 0.3274659812450409, 'eval_runtime': 2.3098, 'eval_samples_per_second': 334.657, 'eval_steps_per_second': 21.214, 'epoch': 2.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 92%|█████████▏| 1200/1305 [07:23<00:35,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.24191461836998707, 'eval_f1': 0.46024204143804465, 'eval_loss': 0.3241020739078522, 'eval_runtime': 2.3176, 'eval_samples_per_second': 333.54, 'eval_steps_per_second': 21.143, 'epoch': 2.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|█████████▉| 1300/1305 [08:00<00:01,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.24191461836998707, 'eval_f1': 0.4482068001912287, 'eval_loss': 0.32208094000816345, 'eval_runtime': 2.2987, 'eval_samples_per_second': 336.276, 'eval_steps_per_second': 21.316, 'epoch': 2.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1305/1305 [08:02<00:00,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 490.9241, 'train_samples_per_second': 42.477, 'train_steps_per_second': 2.658, 'train_loss': 0.32928414180360993, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1305, training_loss=0.32928414180360993, metrics={'train_runtime': 490.9241, 'train_samples_per_second': 42.477, 'train_steps_per_second': 2.658, 'train_loss': 0.32928414180360993, 'epoch': 3.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 435/435 [00:18<00:00, 23.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.3195223708818875,\n",
       " 'eval_f1': 0.5019881509278004,\n",
       " 'eval_loss': 0.26109328866004944,\n",
       " 'eval_runtime': 18.6019,\n",
       " 'eval_samples_per_second': 373.671,\n",
       " 'eval_steps_per_second': 23.385,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(trainset_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:02<00:00, 23.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.24191461836998707,\n",
       " 'eval_f1': 0.4482068001912287,\n",
       " 'eval_loss': 0.32208094000816345,\n",
       " 'eval_runtime': 2.1253,\n",
       " 'eval_samples_per_second': 363.715,\n",
       " 'eval_steps_per_second': 23.056,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(validset_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Base Uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "    return tokenizer(text = batch[\"texts\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6951/6951 [00:00<00:00, 17877.90 examples/s]\n",
      "Map: 100%|██████████| 773/773 [00:00<00:00, 22309.82 examples/s]\n"
     ]
    }
   ],
   "source": [
    "trainset_tokenized = trainset.map(tokenize_fn, batched=True)\n",
    "validset_tokenized = validset.map(tokenize_fn, batched=True)\n",
    "trainset_tokenized = trainset_tokenized.remove_columns(['texts'])\n",
    "validset_tokenized = validset_tokenized.remove_columns(['texts'])\n",
    "trainset_tokenized.set_format(type='torch')\n",
    "validset_tokenized.set_format(type='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, \n",
    "    problem_type=\"multi_label_classification\", \n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=3,\n",
    "\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,  \n",
    "    learning_rate=2e-5, \n",
    "    optim='adamw_torch',\n",
    "\n",
    "    # Checkpoint saving and model evaluation settings\n",
    "    output_dir=str(model_folder/'bert'), \n",
    "    evaluation_strategy='steps', \n",
    "    eval_steps=100, \n",
    "    save_strategy=\"steps\", \n",
    "    save_steps=100, \n",
    "    load_best_model_at_end=True, \n",
    "    save_total_limit=2, \n",
    "    metric_for_best_model=\"loss\",\n",
    "    greater_is_better=False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shaur\\anaconda3\\envs\\anlp\\lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=trainset_tokenized,\n",
    "    eval_dataset=validset_tokenized,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshauryat1298\u001b[0m (\u001b[33mshauryat12\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\shaur\\Desktop\\UTD\\ANLP\\Assignments\\Emotion Detection\\wandb\\run-20240405_171922-etjzw2v9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shauryat12/huggingface/runs/etjzw2v9/workspace' target=\"_blank\">changeling-holosuite-8</a></strong> to <a href='https://wandb.ai/shauryat12/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shauryat12/huggingface' target=\"_blank\">https://wandb.ai/shauryat12/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shauryat12/huggingface/runs/etjzw2v9/workspace' target=\"_blank\">https://wandb.ai/shauryat12/huggingface/runs/etjzw2v9/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      "  8%|▊         | 100/1305 [01:03<11:50,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.11642949547218628, 'eval_f1': 0.2019508057022394, 'eval_loss': 0.41748642921447754, 'eval_runtime': 4.3605, 'eval_samples_per_second': 177.272, 'eval_steps_per_second': 11.237, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 15%|█▌        | 200/1305 [02:08<10:55,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.17723156532988357, 'eval_f1': 0.2537389419746899, 'eval_loss': 0.38499629497528076, 'eval_runtime': 4.3406, 'eval_samples_per_second': 178.087, 'eval_steps_per_second': 11.289, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 23%|██▎       | 300/1305 [03:13<09:44,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.20439844760672704, 'eval_f1': 0.3538639585209382, 'eval_loss': 0.3684843182563782, 'eval_runtime': 4.3513, 'eval_samples_per_second': 177.648, 'eval_steps_per_second': 11.261, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 31%|███       | 400/1305 [04:17<08:47,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.2095730918499353, 'eval_f1': 0.38675899521200385, 'eval_loss': 0.3482501804828644, 'eval_runtime': 4.3675, 'eval_samples_per_second': 176.99, 'eval_steps_per_second': 11.219, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 500/1305 [05:18<07:49,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.392, 'grad_norm': 1.398733139038086, 'learning_rate': 1.2337164750957855e-05, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 38%|███▊      | 500/1305 [05:22<07:49,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.240620957309185, 'eval_f1': 0.4203034534258016, 'eval_loss': 0.3373161256313324, 'eval_runtime': 4.0349, 'eval_samples_per_second': 191.58, 'eval_steps_per_second': 12.144, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 46%|████▌     | 600/1305 [06:28<06:58,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.2445019404915912, 'eval_f1': 0.4417213767515847, 'eval_loss': 0.33114317059516907, 'eval_runtime': 4.3705, 'eval_samples_per_second': 176.869, 'eval_steps_per_second': 11.212, 'epoch': 1.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 54%|█████▎    | 700/1305 [07:33<06:06,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.23803363518758086, 'eval_f1': 0.41672031745894134, 'eval_loss': 0.3276364207267761, 'eval_runtime': 4.3553, 'eval_samples_per_second': 177.487, 'eval_steps_per_second': 11.251, 'epoch': 1.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 61%|██████▏   | 800/1305 [08:38<05:07,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.24708926261319533, 'eval_f1': 0.42460476091382254, 'eval_loss': 0.32599061727523804, 'eval_runtime': 4.3591, 'eval_samples_per_second': 177.33, 'eval_steps_per_second': 11.241, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 69%|██████▉   | 900/1305 [09:43<03:55,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.2522639068564036, 'eval_f1': 0.43623715167172517, 'eval_loss': 0.321305513381958, 'eval_runtime': 4.3565, 'eval_samples_per_second': 177.436, 'eval_steps_per_second': 11.248, 'epoch': 2.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1000/1305 [10:43<02:59,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2925, 'grad_norm': 1.355248212814331, 'learning_rate': 4.674329501915709e-06, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 77%|███████▋  | 1000/1305 [10:48<02:59,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.24967658473479948, 'eval_f1': 0.45298285054319015, 'eval_loss': 0.3206462562084198, 'eval_runtime': 4.0892, 'eval_samples_per_second': 189.032, 'eval_steps_per_second': 11.983, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 84%|████████▍ | 1100/1305 [11:53<02:02,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.24967658473479948, 'eval_f1': 0.45880905954592444, 'eval_loss': 0.3223540484905243, 'eval_runtime': 4.4712, 'eval_samples_per_second': 172.886, 'eval_steps_per_second': 10.959, 'epoch': 2.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 92%|█████████▏| 1200/1305 [12:59<01:01,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.24967658473479948, 'eval_f1': 0.4678171557225619, 'eval_loss': 0.32194480299949646, 'eval_runtime': 4.3396, 'eval_samples_per_second': 178.127, 'eval_steps_per_second': 11.291, 'epoch': 2.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|█████████▉| 1300/1305 [14:04<00:02,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.24708926261319533, 'eval_f1': 0.4587338686303221, 'eval_loss': 0.31893399357795715, 'eval_runtime': 4.3463, 'eval_samples_per_second': 177.851, 'eval_steps_per_second': 11.274, 'epoch': 2.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1305/1305 [14:10<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 859.935, 'train_samples_per_second': 24.25, 'train_steps_per_second': 1.518, 'train_loss': 0.3251488638106891, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1305, training_loss=0.3251488638106891, metrics={'train_runtime': 859.935, 'train_samples_per_second': 24.25, 'train_steps_per_second': 1.518, 'train_loss': 0.3251488638106891, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 435/435 [00:35<00:00, 12.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.3467127032081715,\n",
       " 'eval_f1': 0.5303069348003384,\n",
       " 'eval_loss': 0.24998746812343597,\n",
       " 'eval_runtime': 35.6878,\n",
       " 'eval_samples_per_second': 194.773,\n",
       " 'eval_steps_per_second': 12.189,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(trainset_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:03<00:00, 12.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.24708926261319533,\n",
       " 'eval_f1': 0.4587338686303221,\n",
       " 'eval_loss': 0.31893399357795715,\n",
       " 'eval_runtime': 4.0667,\n",
       " 'eval_samples_per_second': 190.079,\n",
       " 'eval_steps_per_second': 12.049,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(validset_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberta Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shaur\\anaconda3\\envs\\anlp\\lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\shaur\\.cache\\huggingface\\hub\\models--roberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "    return tokenizer(text = batch[\"texts\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6951/6951 [00:00<00:00, 50999.19 examples/s]\n",
      "Map: 100%|██████████| 773/773 [00:00<00:00, 48356.36 examples/s]\n"
     ]
    }
   ],
   "source": [
    "trainset_tokenized = trainset.map(tokenize_fn, batched=True)\n",
    "validset_tokenized = validset.map(tokenize_fn, batched=True)\n",
    "trainset_tokenized = trainset_tokenized.remove_columns(['texts'])\n",
    "validset_tokenized = validset_tokenized.remove_columns(['texts'])\n",
    "trainset_tokenized.set_format(type='torch')\n",
    "validset_tokenized.set_format(type='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, \n",
    "    problem_type=\"multi_label_classification\", \n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=3,\n",
    "\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,  \n",
    "    learning_rate=2e-5, \n",
    "    optim='adamw_torch',\n",
    "\n",
    "    # Checkpoint saving and model evaluation settings\n",
    "    output_dir=str(model_folder/'bert'), \n",
    "    evaluation_strategy='steps', \n",
    "    eval_steps=100, \n",
    "    save_strategy=\"steps\", \n",
    "    save_steps=100, \n",
    "    load_best_model_at_end=True, \n",
    "    save_total_limit=2, \n",
    "    metric_for_best_model=\"loss\",\n",
    "    greater_is_better=False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shaur\\anaconda3\\envs\\anlp\\lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=trainset_tokenized,\n",
    "    eval_dataset=validset_tokenized,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      "  8%|▊         | 100/1305 [01:08<12:59,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.12807244501940493, 'eval_f1': 0.2257423799023587, 'eval_loss': 0.4027841091156006, 'eval_runtime': 4.4292, 'eval_samples_per_second': 174.524, 'eval_steps_per_second': 11.063, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 15%|█▌        | 200/1305 [02:19<11:47,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.2056921086675291, 'eval_f1': 0.35617407297684045, 'eval_loss': 0.3598071038722992, 'eval_runtime': 4.4221, 'eval_samples_per_second': 174.802, 'eval_steps_per_second': 11.081, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 23%|██▎       | 300/1305 [03:29<10:36,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.24967658473479948, 'eval_f1': 0.414257386459418, 'eval_loss': 0.34112808108329773, 'eval_runtime': 4.3663, 'eval_samples_per_second': 177.039, 'eval_steps_per_second': 11.222, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 31%|███       | 400/1305 [04:40<09:37,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.23673997412677877, 'eval_f1': 0.4302804937038325, 'eval_loss': 0.3303414583206177, 'eval_runtime': 4.3975, 'eval_samples_per_second': 175.781, 'eval_steps_per_second': 11.143, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 500/1305 [05:46<08:36,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3725, 'grad_norm': 2.8976891040802, 'learning_rate': 1.2337164750957855e-05, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 38%|███▊      | 500/1305 [05:50<08:36,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.24191461836998707, 'eval_f1': 0.4691136679182259, 'eval_loss': 0.3292178511619568, 'eval_runtime': 3.9981, 'eval_samples_per_second': 193.343, 'eval_steps_per_second': 12.256, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 46%|████▌     | 600/1305 [07:00<07:30,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.25097024579560157, 'eval_f1': 0.4649295207572138, 'eval_loss': 0.3220827877521515, 'eval_runtime': 4.364, 'eval_samples_per_second': 177.132, 'eval_steps_per_second': 11.228, 'epoch': 1.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 54%|█████▎    | 700/1305 [08:10<06:40,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.24967658473479948, 'eval_f1': 0.44132394722855106, 'eval_loss': 0.31901153922080994, 'eval_runtime': 4.3695, 'eval_samples_per_second': 176.907, 'eval_steps_per_second': 11.214, 'epoch': 1.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 61%|██████▏   | 800/1305 [09:20<05:25,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.26002587322121606, 'eval_f1': 0.45018902779564646, 'eval_loss': 0.31287574768066406, 'eval_runtime': 4.3807, 'eval_samples_per_second': 176.456, 'eval_steps_per_second': 11.185, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 69%|██████▉   | 900/1305 [10:30<04:15,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.2677878395860285, 'eval_f1': 0.47326536982469114, 'eval_loss': 0.3140874207019806, 'eval_runtime': 4.3812, 'eval_samples_per_second': 176.434, 'eval_steps_per_second': 11.184, 'epoch': 2.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1000/1305 [11:36<03:13,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.294, 'grad_norm': 2.1148295402526855, 'learning_rate': 4.674329501915709e-06, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 77%|███████▋  | 1000/1305 [11:40<03:13,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.2613195342820181, 'eval_f1': 0.4734100270696352, 'eval_loss': 0.30876976251602173, 'eval_runtime': 3.9976, 'eval_samples_per_second': 193.367, 'eval_steps_per_second': 12.257, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 84%|████████▍ | 1100/1305 [12:50<02:10,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.2664941785252264, 'eval_f1': 0.4843589357770723, 'eval_loss': 0.3123122453689575, 'eval_runtime': 4.3577, 'eval_samples_per_second': 177.389, 'eval_steps_per_second': 11.245, 'epoch': 2.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 92%|█████████▏| 1200/1305 [14:00<01:07,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.2652005174644243, 'eval_f1': 0.5018885230867204, 'eval_loss': 0.3105187714099884, 'eval_runtime': 4.3572, 'eval_samples_per_second': 177.406, 'eval_steps_per_second': 11.246, 'epoch': 2.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|█████████▉| 1300/1305 [15:10<00:03,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.2613195342820181, 'eval_f1': 0.49549515494873986, 'eval_loss': 0.30794021487236023, 'eval_runtime': 4.3624, 'eval_samples_per_second': 177.195, 'eval_steps_per_second': 11.232, 'epoch': 2.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1305/1305 [15:15<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 915.7151, 'train_samples_per_second': 22.772, 'train_steps_per_second': 1.425, 'train_loss': 0.31927538758493473, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1305, training_loss=0.31927538758493473, metrics={'train_runtime': 915.7151, 'train_samples_per_second': 22.772, 'train_steps_per_second': 1.425, 'train_loss': 0.31927538758493473, 'epoch': 3.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 435/435 [00:34<00:00, 12.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.33505970363976406,\n",
       " 'eval_f1': 0.5472622066111421,\n",
       " 'eval_loss': 0.2523092031478882,\n",
       " 'eval_runtime': 34.996,\n",
       " 'eval_samples_per_second': 198.623,\n",
       " 'eval_steps_per_second': 12.43,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(trainset_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:03<00:00, 12.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.2613195342820181,\n",
       " 'eval_f1': 0.49549515494873986,\n",
       " 'eval_loss': 0.30794021487236023,\n",
       " 'eval_runtime': 3.9362,\n",
       " 'eval_samples_per_second': 196.382,\n",
       " 'eval_steps_per_second': 12.449,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(validset_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Albert Base V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shaur\\anaconda3\\envs\\anlp\\lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\shaur\\.cache\\huggingface\\hub\\models--albert-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"albert-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "    return tokenizer(text = batch[\"texts\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6951/6951 [00:00<00:00, 25367.98 examples/s]\n",
      "Map: 100%|██████████| 773/773 [00:00<00:00, 21448.21 examples/s]\n"
     ]
    }
   ],
   "source": [
    "trainset_tokenized = trainset.map(tokenize_fn, batched=True)\n",
    "validset_tokenized = validset.map(tokenize_fn, batched=True)\n",
    "trainset_tokenized = trainset_tokenized.remove_columns(['texts'])\n",
    "validset_tokenized = validset_tokenized.remove_columns(['texts'])\n",
    "trainset_tokenized.set_format(type='torch')\n",
    "validset_tokenized.set_format(type='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, \n",
    "    problem_type=\"multi_label_classification\", \n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=3,\n",
    "\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,  \n",
    "    learning_rate=2e-5, \n",
    "    optim='adamw_torch',\n",
    "\n",
    "    # Checkpoint saving and model evaluation settings\n",
    "    output_dir=str(model_folder/'bert'), \n",
    "    evaluation_strategy='steps', \n",
    "    eval_steps=100, \n",
    "    save_strategy=\"steps\", \n",
    "    save_steps=100, \n",
    "    load_best_model_at_end=True, \n",
    "    save_total_limit=2, \n",
    "    metric_for_best_model=\"loss\",\n",
    "    greater_is_better=False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shaur\\anaconda3\\envs\\anlp\\lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=trainset_tokenized,\n",
    "    eval_dataset=validset_tokenized,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshauryat1298\u001b[0m (\u001b[33mshauryat12\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\shaur\\Desktop\\UTD\\ANLP\\Assignments\\Emotion Detection\\wandb\\run-20240405_190036-fa0zd97r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shauryat12/huggingface/runs/fa0zd97r/workspace' target=\"_blank\">andorian-queen-9</a></strong> to <a href='https://wandb.ai/shauryat12/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shauryat12/huggingface' target=\"_blank\">https://wandb.ai/shauryat12/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shauryat12/huggingface/runs/fa0zd97r/workspace' target=\"_blank\">https://wandb.ai/shauryat12/huggingface/runs/fa0zd97r/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      "  8%|▊         | 100/1305 [00:47<08:13,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.12807244501940493, 'eval_f1': 0.22535316264318997, 'eval_loss': 0.4130074381828308, 'eval_runtime': 6.0863, 'eval_samples_per_second': 127.007, 'eval_steps_per_second': 8.051, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 15%|█▌        | 200/1305 [01:35<07:27,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.1759379042690815, 'eval_f1': 0.29899779084443245, 'eval_loss': 0.3931446671485901, 'eval_runtime': 6.0939, 'eval_samples_per_second': 126.848, 'eval_steps_per_second': 8.041, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 23%|██▎       | 300/1305 [02:21<06:36,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.18628719275549807, 'eval_f1': 0.29488472657299003, 'eval_loss': 0.3715600073337555, 'eval_runtime': 6.091, 'eval_samples_per_second': 126.909, 'eval_steps_per_second': 8.045, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 31%|███       | 400/1305 [03:08<06:07,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.20439844760672704, 'eval_f1': 0.3456595234453906, 'eval_loss': 0.35690903663635254, 'eval_runtime': 6.076, 'eval_samples_per_second': 127.222, 'eval_steps_per_second': 8.065, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 500/1305 [03:49<05:13,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3887, 'grad_norm': 5.95774507522583, 'learning_rate': 1.2337164750957855e-05, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 38%|███▊      | 500/1305 [03:55<05:13,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.22509702457956016, 'eval_f1': 0.38196447449574134, 'eval_loss': 0.3521788418292999, 'eval_runtime': 6.0641, 'eval_samples_per_second': 127.471, 'eval_steps_per_second': 8.08, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 46%|████▌     | 600/1305 [04:43<04:48,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.2445019404915912, 'eval_f1': 0.4164110628744058, 'eval_loss': 0.33879250288009644, 'eval_runtime': 6.0968, 'eval_samples_per_second': 126.788, 'eval_steps_per_second': 8.037, 'epoch': 1.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 54%|█████▎    | 700/1305 [05:30<04:20,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.23932729624838292, 'eval_f1': 0.4084813952830547, 'eval_loss': 0.3319978415966034, 'eval_runtime': 6.0978, 'eval_samples_per_second': 126.767, 'eval_steps_per_second': 8.036, 'epoch': 1.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 61%|██████▏   | 800/1305 [06:17<03:35,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.2535575679172057, 'eval_f1': 0.4243455658954676, 'eval_loss': 0.326185405254364, 'eval_runtime': 6.0858, 'eval_samples_per_second': 127.017, 'eval_steps_per_second': 8.052, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 69%|██████▉   | 900/1305 [07:04<02:37,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.25485122897800777, 'eval_f1': 0.4453089806345318, 'eval_loss': 0.3269825577735901, 'eval_runtime': 6.0847, 'eval_samples_per_second': 127.041, 'eval_steps_per_second': 8.053, 'epoch': 2.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1000/1305 [07:45<02:01,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3035, 'grad_norm': 4.277917861938477, 'learning_rate': 4.674329501915709e-06, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 77%|███████▋  | 1000/1305 [07:51<02:01,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.25614489003880986, 'eval_f1': 0.4476056719551332, 'eval_loss': 0.31974953413009644, 'eval_runtime': 6.0583, 'eval_samples_per_second': 127.593, 'eval_steps_per_second': 8.088, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 84%|████████▍ | 1100/1305 [08:37<01:24,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.24967658473479948, 'eval_f1': 0.455979057285635, 'eval_loss': 0.3214360177516937, 'eval_runtime': 6.1029, 'eval_samples_per_second': 126.66, 'eval_steps_per_second': 8.029, 'epoch': 2.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 92%|█████████▏| 1200/1305 [09:25<00:42,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.25485122897800777, 'eval_f1': 0.4652791358704587, 'eval_loss': 0.3193603754043579, 'eval_runtime': 6.0906, 'eval_samples_per_second': 126.917, 'eval_steps_per_second': 8.045, 'epoch': 2.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|█████████▉| 1300/1305 [10:12<00:02,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.26390685640362227, 'eval_f1': 0.4629353959323966, 'eval_loss': 0.31694474816322327, 'eval_runtime': 6.0877, 'eval_samples_per_second': 126.976, 'eval_steps_per_second': 8.049, 'epoch': 2.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1305/1305 [10:14<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 622.6521, 'train_samples_per_second': 33.491, 'train_steps_per_second': 2.096, 'train_loss': 0.3300281802356472, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1305, training_loss=0.3300281802356472, metrics={'train_runtime': 622.6521, 'train_samples_per_second': 33.491, 'train_steps_per_second': 2.096, 'train_loss': 0.3300281802356472, 'epoch': 3.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 435/435 [00:54<00:00,  7.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.32297511149474895,\n",
       " 'eval_f1': 0.511961651962669,\n",
       " 'eval_loss': 0.2644408345222473,\n",
       " 'eval_runtime': 54.5441,\n",
       " 'eval_samples_per_second': 127.438,\n",
       " 'eval_steps_per_second': 7.975,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(trainset_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:05<00:00,  8.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.26390685640362227,\n",
       " 'eval_f1': 0.4629353959323966,\n",
       " 'eval_loss': 0.31694474816322327,\n",
       " 'eval_runtime': 5.9872,\n",
       " 'eval_samples_per_second': 129.109,\n",
       " 'eval_steps_per_second': 8.184,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(validset_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deberta V3 Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shaur\\anaconda3\\envs\\anlp\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"microsoft/deberta-v3-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "    return tokenizer(text = batch[\"texts\"], truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6951/6951 [00:00<00:00, 38497.38 examples/s]\n",
      "Map: 100%|██████████| 773/773 [00:00<00:00, 41403.14 examples/s]\n"
     ]
    }
   ],
   "source": [
    "trainset_tokenized = trainset.map(tokenize_fn, batched=True)\n",
    "validset_tokenized = validset.map(tokenize_fn, batched=True)\n",
    "trainset_tokenized = trainset_tokenized.remove_columns(['texts'])\n",
    "validset_tokenized = validset_tokenized.remove_columns(['texts'])\n",
    "trainset_tokenized.set_format(type='torch')\n",
    "validset_tokenized.set_format(type='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shaur\\anaconda3\\envs\\anlp\\lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\shaur\\.cache\\huggingface\\hub\\models--microsoft--deberta-v3-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, \n",
    "    problem_type=\"multi_label_classification\", \n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=3,\n",
    "\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,  \n",
    "    learning_rate=2e-5, \n",
    "    optim='adamw_torch',\n",
    "\n",
    "    # Checkpoint saving and model evaluation settings\n",
    "    output_dir=str(model_folder/'bert'), \n",
    "    evaluation_strategy='steps', \n",
    "    eval_steps=100, \n",
    "    save_strategy=\"steps\", \n",
    "    save_steps=100, \n",
    "    load_best_model_at_end=True, \n",
    "    save_total_limit=2, \n",
    "    metric_for_best_model=\"loss\",\n",
    "    greater_is_better=False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shaur\\anaconda3\\envs\\anlp\\lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=trainset_tokenized,\n",
    "    eval_dataset=validset_tokenized,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshauryat1298\u001b[0m (\u001b[33mshauryat12\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\shaur\\Desktop\\UTD\\ANLP\\Assignments\\Emotion Detection\\wandb\\run-20240405_195115-e9jxnfpw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shauryat12/huggingface/runs/e9jxnfpw/workspace' target=\"_blank\">crusher-phaser-11</a></strong> to <a href='https://wandb.ai/shauryat12/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shauryat12/huggingface' target=\"_blank\">https://wandb.ai/shauryat12/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shauryat12/huggingface/runs/e9jxnfpw/workspace' target=\"_blank\">https://wandb.ai/shauryat12/huggingface/runs/e9jxnfpw/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      "  8%|▊         | 100/1305 [01:56<21:41,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.062095730918499355, 'eval_f1': 0.17225961192325134, 'eval_loss': 0.42655500769615173, 'eval_runtime': 8.7874, 'eval_samples_per_second': 87.966, 'eval_steps_per_second': 5.576, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 15%|█▌        | 200/1305 [03:54<19:50,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.17852522639068563, 'eval_f1': 0.2522879002203507, 'eval_loss': 0.3916710913181305, 'eval_runtime': 8.7447, 'eval_samples_per_second': 88.396, 'eval_steps_per_second': 5.603, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 23%|██▎       | 300/1305 [05:53<17:48,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.15782664941785252, 'eval_f1': 0.24969737461058397, 'eval_loss': 0.37028956413269043, 'eval_runtime': 8.7703, 'eval_samples_per_second': 88.138, 'eval_steps_per_second': 5.587, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 31%|███       | 400/1305 [07:52<16:07,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.19146183699870634, 'eval_f1': 0.30733062136343936, 'eval_loss': 0.35956719517707825, 'eval_runtime': 8.73, 'eval_samples_per_second': 88.545, 'eval_steps_per_second': 5.613, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 500/1305 [09:42<14:20,  1.07s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3961, 'grad_norm': 1.6336902379989624, 'learning_rate': 1.2337164750957855e-05, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 38%|███▊      | 500/1305 [09:50<14:20,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.20827943078913325, 'eval_f1': 0.3530428277975439, 'eval_loss': 0.3609142303466797, 'eval_runtime': 8.1639, 'eval_samples_per_second': 94.685, 'eval_steps_per_second': 6.002, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 46%|████▌     | 600/1305 [11:49<12:40,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.22121604139715395, 'eval_f1': 0.3932244955418941, 'eval_loss': 0.34530046582221985, 'eval_runtime': 8.7336, 'eval_samples_per_second': 88.509, 'eval_steps_per_second': 5.611, 'epoch': 1.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 54%|█████▎    | 700/1305 [13:48<11:03,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.21216041397153945, 'eval_f1': 0.4062863009563545, 'eval_loss': 0.33775848150253296, 'eval_runtime': 8.7742, 'eval_samples_per_second': 88.099, 'eval_steps_per_second': 5.585, 'epoch': 1.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 61%|██████▏   | 800/1305 [15:47<09:06,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.24579560155239327, 'eval_f1': 0.4281291965316268, 'eval_loss': 0.33155593276023865, 'eval_runtime': 8.7379, 'eval_samples_per_second': 88.466, 'eval_steps_per_second': 5.608, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 69%|██████▉   | 900/1305 [17:45<07:11,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.2276843467011643, 'eval_f1': 0.43119653662495805, 'eval_loss': 0.3265916109085083, 'eval_runtime': 8.771, 'eval_samples_per_second': 88.132, 'eval_steps_per_second': 5.587, 'epoch': 2.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1000/1305 [19:35<05:25,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3098, 'grad_norm': 1.1111587285995483, 'learning_rate': 4.674329501915709e-06, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 77%|███████▋  | 1000/1305 [19:44<05:25,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.24191461836998707, 'eval_f1': 0.4555556788018384, 'eval_loss': 0.3253052234649658, 'eval_runtime': 8.1394, 'eval_samples_per_second': 94.97, 'eval_steps_per_second': 6.02, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 84%|████████▍ | 1100/1305 [21:42<03:39,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.22639068564036222, 'eval_f1': 0.45819021280906236, 'eval_loss': 0.3282020688056946, 'eval_runtime': 8.7614, 'eval_samples_per_second': 88.228, 'eval_steps_per_second': 5.593, 'epoch': 2.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 92%|█████████▏| 1200/1305 [23:41<01:53,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.24320827943078913, 'eval_f1': 0.47174571720542874, 'eval_loss': 0.32118818163871765, 'eval_runtime': 8.7353, 'eval_samples_per_second': 88.491, 'eval_steps_per_second': 5.609, 'epoch': 2.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|█████████▉| 1300/1305 [25:40<00:05,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.24191461836998707, 'eval_f1': 0.464928618741709, 'eval_loss': 0.31953272223472595, 'eval_runtime': 8.8618, 'eval_samples_per_second': 87.228, 'eval_steps_per_second': 5.529, 'epoch': 2.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1305/1305 [25:49<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1556.8584, 'train_samples_per_second': 13.394, 'train_steps_per_second': 0.838, 'train_loss': 0.33648407450124224, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1305, training_loss=0.33648407450124224, metrics={'train_runtime': 1556.8584, 'train_samples_per_second': 13.394, 'train_steps_per_second': 0.838, 'train_loss': 0.33648407450124224, 'epoch': 3.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 435/435 [01:12<00:00,  5.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.3100273341965185,\n",
       " 'eval_f1': 0.5101161867221161,\n",
       " 'eval_loss': 0.26065361499786377,\n",
       " 'eval_runtime': 73.1274,\n",
       " 'eval_samples_per_second': 95.053,\n",
       " 'eval_steps_per_second': 5.949,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(trainset_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:07<00:00,  6.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.24191461836998707,\n",
       " 'eval_f1': 0.464928618741709,\n",
       " 'eval_loss': 0.31953272223472595,\n",
       " 'eval_runtime': 8.1392,\n",
       " 'eval_samples_per_second': 94.973,\n",
       " 'eval_steps_per_second': 6.02,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(validset_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shaur\\anaconda3\\envs\\anlp\\lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\shaur\\.cache\\huggingface\\hub\\models--cardiffnlp--twitter-roberta-base-emotion-multilabel-latest. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"cardiffnlp/twitter-roberta-base-emotion-multilabel-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "    return tokenizer(text = batch[\"texts\"], truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6951/6951 [00:00<00:00, 18015.11 examples/s]\n",
      "Map: 100%|██████████| 773/773 [00:00<00:00, 20781.32 examples/s]\n"
     ]
    }
   ],
   "source": [
    "trainset_tokenized = trainset.map(tokenize_fn, batched=True)\n",
    "validset_tokenized = validset.map(tokenize_fn, batched=True)\n",
    "trainset_tokenized = trainset_tokenized.remove_columns(['texts'])\n",
    "validset_tokenized = validset_tokenized.remove_columns(['texts'])\n",
    "trainset_tokenized.set_format(type='torch')\n",
    "validset_tokenized.set_format(type='torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, \n",
    "    problem_type=\"multi_label_classification\", \n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=3,\n",
    "\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    optim='adamw_torch',\n",
    "\n",
    "    # Checkpoint saving and model evaluation settings\n",
    "    output_dir=str(model_folder/'roberta_base_emotion'), \n",
    "    evaluation_strategy='steps', \n",
    "    eval_steps=100, \n",
    "    save_strategy=\"steps\", \n",
    "    save_steps=100, \n",
    "    load_best_model_at_end=True, \n",
    "    save_total_limit=2, \n",
    "    metric_for_best_model=\"loss\",\n",
    "    greater_is_better=False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=trainset_tokenized,\n",
    "    eval_dataset=validset_tokenized,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      "  8%|▊         | 100/1305 [01:05<12:11,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.2949547218628719, 'eval_f1': 0.5780410973159245, 'eval_loss': 0.268928587436676, 'eval_runtime': 4.3623, 'eval_samples_per_second': 177.202, 'eval_steps_per_second': 11.233, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 15%|█▌        | 200/1305 [02:11<11:09,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.31565329883570503, 'eval_f1': 0.5934336355545805, 'eval_loss': 0.26409852504730225, 'eval_runtime': 4.3488, 'eval_samples_per_second': 177.751, 'eval_steps_per_second': 11.268, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 23%|██▎       | 300/1305 [03:18<10:02,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.3298835705045278, 'eval_f1': 0.6136405774450596, 'eval_loss': 0.2595262825489044, 'eval_runtime': 4.3616, 'eval_samples_per_second': 177.227, 'eval_steps_per_second': 11.234, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 31%|███       | 400/1305 [04:24<09:07,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.32858990944372574, 'eval_f1': 0.6034455521975072, 'eval_loss': 0.25941359996795654, 'eval_runtime': 4.3804, 'eval_samples_per_second': 176.469, 'eval_steps_per_second': 11.186, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 500/1305 [05:28<08:07,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2632, 'grad_norm': 2.102485418319702, 'learning_rate': 3.084291187739464e-05, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 38%|███▊      | 500/1305 [05:32<08:07,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.3182406209573092, 'eval_f1': 0.6307706455060099, 'eval_loss': 0.25718170404434204, 'eval_runtime': 4.0095, 'eval_samples_per_second': 192.793, 'eval_steps_per_second': 12.221, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 46%|████▌     | 600/1305 [06:39<07:08,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.3208279430789133, 'eval_f1': 0.6265111017525696, 'eval_loss': 0.26307937502861023, 'eval_runtime': 4.3698, 'eval_samples_per_second': 176.895, 'eval_steps_per_second': 11.213, 'epoch': 1.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 54%|█████▎    | 700/1305 [07:45<06:19,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.3221216041397154, 'eval_f1': 0.5976645206873225, 'eval_loss': 0.2657506763935089, 'eval_runtime': 4.3242, 'eval_samples_per_second': 178.76, 'eval_steps_per_second': 11.331, 'epoch': 1.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 61%|██████▏   | 800/1305 [08:52<05:08,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.3389391979301423, 'eval_f1': 0.6270367974421162, 'eval_loss': 0.25857657194137573, 'eval_runtime': 4.3211, 'eval_samples_per_second': 178.89, 'eval_steps_per_second': 11.34, 'epoch': 1.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 69%|██████▉   | 900/1305 [09:58<04:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.34799482535575677, 'eval_f1': 0.6538759842554811, 'eval_loss': 0.25490421056747437, 'eval_runtime': 4.3319, 'eval_samples_per_second': 178.443, 'eval_steps_per_second': 11.311, 'epoch': 2.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1000/1305 [11:01<03:02,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2128, 'grad_norm': 1.969548225402832, 'learning_rate': 1.1685823754789272e-05, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 77%|███████▋  | 1000/1305 [11:04<03:02,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.34670116429495473, 'eval_f1': 0.6508656154418752, 'eval_loss': 0.2602125406265259, 'eval_runtime': 3.9606, 'eval_samples_per_second': 195.175, 'eval_steps_per_second': 12.372, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 84%|████████▍ | 1100/1305 [12:10<02:03,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.3389391979301423, 'eval_f1': 0.6587079072479786, 'eval_loss': 0.2580501139163971, 'eval_runtime': 4.32, 'eval_samples_per_second': 178.935, 'eval_steps_per_second': 11.343, 'epoch': 2.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 92%|█████████▏| 1200/1305 [13:17<01:03,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.33247089262613194, 'eval_f1': 0.6645862879644328, 'eval_loss': 0.2599320709705353, 'eval_runtime': 4.3401, 'eval_samples_per_second': 178.108, 'eval_steps_per_second': 11.29, 'epoch': 2.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|█████████▉| 1300/1305 [14:24<00:02,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_accuracy': 0.35834411384217335, 'eval_f1': 0.6631309024646961, 'eval_loss': 0.25456538796424866, 'eval_runtime': 4.3392, 'eval_samples_per_second': 178.142, 'eval_steps_per_second': 11.292, 'epoch': 2.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1305/1305 [14:28<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 868.9618, 'train_samples_per_second': 23.998, 'train_steps_per_second': 1.502, 'train_loss': 0.22507325972633802, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1305, training_loss=0.22507325972633802, metrics={'train_runtime': 868.9618, 'train_samples_per_second': 23.998, 'train_steps_per_second': 1.502, 'train_loss': 0.22507325972633802, 'epoch': 3.0})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
